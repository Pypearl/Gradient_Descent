# Gradient Descent [![Profile][title-img]][profile]

[title-img]:https://img.shields.io/badge/-SCIA--PRIME-red
[profile]:https://github.com/Pypearl

## Objective

This practical work aims to provide the necessary elements to understand the implementations of gradient descents.

Here is an overview of the points covered :
* Defining a set of test functions

* Calculation of the gradient of a function in an approximate way (to cover cases where the explicit calculation of the gradient is impossible or cumbersome).

* The descent in the direction of the Gradient at constant pitch
Pitch optimization by Backtracking

* Choosing a direction other than the gradient 
    * Steepest slope as standard
    * Conjugate gradient

* Acceleration: Momentum, Nesterov, Adam.

* Newton's Method and Quasi-Newton's Method


Throughout the course of the practical work, you will be very careful to validate the validity of the written programs by means of a set of tests. You will look at the influence of the parameters on the convergence. You will compare the advantages of the diferent methods against each other.